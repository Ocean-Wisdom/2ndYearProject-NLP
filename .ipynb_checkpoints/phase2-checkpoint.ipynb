{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0577d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "# word to idx\n",
    "import pickle\n",
    "\n",
    "# our functions\n",
    "import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "60685594",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = {}\n",
    "PATH[\"dataset_classification\"] = \"dataset/classification/\"\n",
    "PATH[\"dataset_phase2\"] = \"dataset/phase2/\"\n",
    "PATH[\"dataset_labeling\"] = \"dataset/seq_labeling/\"\n",
    "PATH[\"music_reviews_train\"] = PATH[\"dataset_classification\"] + \"music_reviews_train.json.gz\"\n",
    "PATH[\"music_reviews_dev\"] = PATH[\"dataset_classification\"] + \"music_reviews_dev.json.gz\"\n",
    "PATH[\"music_reviews_test\"] = PATH[\"dataset_classification\"] + \"music_reviews_test_masked.json.gz\"\n",
    "#PATH[\"news\"] = PATH[\"dataset_phase2\"] + \"review_polarity.tar.gz\"\n",
    "cat_dict = {0: \"negative\", 1:\"positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f62e4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our model\n",
    "model = keras.models.load_model('model/2022-3-28-10-35-36')\n",
    "\n",
    "# load our word to idx\n",
    "sequencer = pickle.load( open( \"model/text_to_seq.p\", \"rb\" ) )\n",
    "sequencer = pickle.loads(sequencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cf1f82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\music\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is not sad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>contrary of  adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am not happy to see her</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This album is a riot to listen to</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rare words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This CD will enchant anyone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rare words</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Sentence  annotation                category\n",
       "index                                                                       \n",
       "0                                    NaN         1.0                     NaN\n",
       "1                        This is not sad         1.0  contrary of  adjective\n",
       "2              I am not happy to see her         0.0                     NaN\n",
       "3      This album is a riot to listen to         1.0              rare words\n",
       "4            This CD will enchant anyone         1.0              rare words"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in google drives\n",
    "test = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQK7Cyu8BP41ZXqoS74SSHvoBRijNmIwU5p5PrB0RgnDbyWn0DdanuLxaaHTi1J5Fdw71IfsjoYhwJY/pub?gid=0&single=true&output=csv',\n",
    "                   # Set first column as rownames in data frame\n",
    "                   index_col=0, error_bad_lines=False\n",
    "                  )\n",
    "  # Same result as @TomAugspurger\n",
    "raw = test.rename(columns={\"Annotation (0: negative, 1: positive)\": \"annotation\"})\n",
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a9d45",
   "metadata": {},
   "source": [
    "1 load our model <br>\n",
    "2 Load the word to idx saved object <br>\n",
    "3 Find 100 sentencies, or write them. Also with tags ( positive-negative) <br>\n",
    "4 Try to fuck it up ( swap the meaning, like \"good\" turn into \"not good\" and check the result <br>\n",
    "5 Check accuracy, report hard cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "85e6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "test_com = []\n",
    "for i in range(len(raw)):\n",
    "    try: \n",
    "        len(raw['Sentence'][i])\n",
    "        test_x.append(raw['Sentence'][i])\n",
    "        test_y.append(raw['annotation'][i])\n",
    "        test_com.append(raw['category'][i])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51596031",
   "metadata": {},
   "source": [
    "Examples from checklist repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e190ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03364298]\n",
      " [0.08741328]\n",
      " [0.98132885]\n",
      " [0.9774271 ]\n",
      " [0.99291337]\n",
      " [0.97609895]\n",
      " [0.02246419]\n",
      " [0.8672054 ]\n",
      " [0.00557798]\n",
      " [0.2615013 ]\n",
      " [0.51934355]\n",
      " [0.8888252 ]\n",
      " [0.05223954]\n",
      " [0.1203514 ]\n",
      " [0.9972443 ]\n",
      " [0.97554773]\n",
      " [0.10521677]\n",
      " [0.27166283]\n",
      " [0.29109138]\n",
      " [0.00293759]\n",
      " [0.9950634 ]\n",
      " [0.02872938]\n",
      " [0.14805478]\n",
      " [0.9898317 ]\n",
      " [0.99254423]\n",
      " [0.99561775]\n",
      " [0.9847883 ]\n",
      " [0.88206863]\n",
      " [0.0240986 ]\n",
      " [0.45422596]\n",
      " [0.9044666 ]\n",
      " [0.15352038]\n",
      " [0.56961346]\n",
      " [0.81451833]\n",
      " [0.17383406]\n",
      " [0.8838049 ]\n",
      " [0.21853077]\n",
      " [0.9964583 ]\n",
      " [0.8800013 ]\n",
      " [0.08838725]\n",
      " [0.9894707 ]\n",
      " [0.32369906]\n",
      " [0.35071245]\n",
      " [0.19414523]]\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\music\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\zeugma\\keras_transformers.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(self.texts_to_sequences(texts))\n"
     ]
    }
   ],
   "source": [
    "# Sentencies\n",
    "Train = ['This is a good day', 'what a hell is going on with the sound of the guitar? I never ever heard this shit before, unbeliveable!']\n",
    "#Train = ['This is bullshit, it sound like an old creppy dog']\n",
    "Labels = ['positive','negative']\n",
    "#Labels = ['negative']\n",
    "Train = ['I was not so nervous when I hear her to shout with me. After we had conversation about the problem, and we reconciled. Now we can speak each other']\n",
    "#Train = ['I was not so nervous when I hear her to shout with me. After we had conversation about the problem. Now we can speak each other']\n",
    "#Train = ['I was not so nervous when I hear her to shout with me. After we had conversation about the problem, now everything is more or lessfine']\n",
    "#Train = ['The atmosphere is attractive, but a little uncomfortable. Anyway, the trip was cheap, we are together, so it is more or less good']\n",
    "#Train = ['I was not so nervous when I hear her to shout with me, its crazy']\n",
    "Train = ['Good old days, when we do not have enough money to eat']\n",
    "Train = ['Actually I am thinking about to end my life in a sport car']\n",
    "Train = ['The LSD was so interesting, I had a intensive, good trip with my friends']\n",
    "Train = [\"worth to buy it, ok\"]\n",
    "Labels = ['positive']\n",
    "Labels_i = [1]\n",
    "# labels to idx\n",
    "#labels = []\n",
    "for i in Labels:\n",
    "    if i == \"positive\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "\n",
    "# Transform the example sentencies for idx\n",
    "#Train_s = sequencer.transform(Train)\n",
    "Train_s = sequencer.transform(test_x)\n",
    "# padding apply\n",
    "def sequence_pad(sequence, padding='pre', maxlen=50):\n",
    "    res = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        sequence,\n",
    "        maxlen=maxlen,\n",
    "        dtype='int32',\n",
    "        padding=padding,\n",
    "        truncating='pre',\n",
    "        value=0.0)\n",
    "    return res\n",
    "padding = \"post\"\n",
    "maxlen = 50\n",
    "\n",
    "X_train_p = sequence_pad(Train_s, padding=padding, maxlen=maxlen)\n",
    "\n",
    "# prediction\n",
    "result = model.predict(X_train_p)\n",
    "print(result)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98a2c0",
   "metadata": {},
   "source": [
    "## Correct or wrong ? -- CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6667c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- wrong, sentence: \n",
      "  This is not sad \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.03364298]\n",
      "--- wrong, sentence: \n",
      "  I used to love everything composed by this artist, but these latest songs have just been bad overall \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.51934355]\n",
      "--- wrong, sentence: \n",
      "  I hated this album when I bought it, but it's actually managed to win me over after listening to it a couple of times \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.1203514]\n",
      "--- wrong, sentence: \n",
      "  This album is so ominous that i've been too afraid to go shopping or even turn off the lights for the past 3 days. You absolutely have to listen to this if you are a fan of horror \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.10521677]\n",
      "--- wrong, sentence: \n",
      "  I simply can't understand this album. I hate the choice of instruments, the song genres are all over the place, yet the songs are still repetitve, but i just can't stop listening to this and i don't know why \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.27166283]\n",
      "--- wrong, sentence: \n",
      "  I love the first song however that's it, and as such I can't recommend it\", \"sentiment \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.9950634]\n",
      "--- wrong, sentence: \n",
      "  The first song is simply amazing, and though the rest are simply terrible that first song is simply so good that it makes up for the price on its own \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.02872938]\n",
      "--- wrong, sentence: \n",
      "  I usually don't like the piano but this cd simply blew me away \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.14805478]\n",
      "--- wrong, sentence: \n",
      "  I dislike everything about this situation  \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.88206863]\n",
      "--- wrong, sentence: \n",
      "  I was not so nervous when I hear her to shout with me. After we had conversation about the problem, now everything is more or lessfine \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.45422596]\n",
      "--- wrong, sentence: \n",
      "  Wow, what a guitar sound! Even I lost my hearing. Maybe I will use this cd as an beer mat \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.9044666]\n",
      "--- wrong, sentence: \n",
      "  Its so funky, but it is not written on the cd. I am a metal guy, but still good \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.15352038]\n",
      "--- wrong, sentence: \n",
      "  Good old days, when we do not have enough money to eat \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.81451833]\n",
      "--- wrong, sentence: \n",
      "  Be happy, this is not sad \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.17383406]\n",
      "--- wrong, sentence: \n",
      "  Actually I am thinking about to end my life in a sport car \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.8838049]\n",
      "--- wrong, sentence: \n",
      "  The LSD was so interesting, I had a good trip with my friends \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.21853077]\n",
      "--- wrong, sentence: \n",
      "  This is an easy day? Yeah, it is easier than a day in a middle of a war without food and weapon \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.9964583]\n",
      "--- wrong, sentence: \n",
      "  Is it a perfect music? This album don't give the answer, don't listen, don't buy and don't waste your time with it \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.8800013]\n",
      "--- wrong, sentence: \n",
      "  BAD BAD BAD'! I LOVE IT \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.08838725]\n",
      "--- wrong, sentence: \n",
      "  I spent hours with it. Every track was like a long wrong dream \n",
      "---- original sentiment  0.0 \n",
      " result raw:  [0.9894707]\n",
      "--- wrong, sentence: \n",
      "  It sounds like an old creepy big green tank. That's what I am waiting from a metal band. GOOOOOOREEEE \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.32369906]\n",
      "--- wrong, sentence: \n",
      "  That's what I am waiting from a metal band, It sounds like an old creepy big green tank, low tuned, loud. Just good. GOOOOOOREEEE!!!! \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.35071245]\n",
      "--- wrong, sentence: \n",
      "  ok, worth to buy it \n",
      "---- original sentiment  1.0 \n",
      " result raw:  [0.19414523]\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "acc = 0\n",
    "acc_count = 0\n",
    "res_final = []\n",
    "wrongly_classified_text = []\n",
    "wrongly_classified_original_sentiment = []\n",
    "all_text = []\n",
    "all_sentiment = []\n",
    "all_categories = []\n",
    "for r in result:\n",
    "    acc_count+=1\n",
    "    if r<threshold:\n",
    "        r = 0\n",
    "        #res_final.append(\"negative\")\n",
    "        res_final.append(0)\n",
    "    if r>threshold:\n",
    "        #res_final.append(\"positive\")\n",
    "        res_final.append(1)\n",
    "        \n",
    "fault_counter = 0\n",
    "cases = 0\n",
    "for i in range(len(result)):\n",
    "    #print(\"index\", i)\n",
    "    #print(\"####\", res_final[i], \"---\", hard_sen_sent[i])\n",
    "    if test_y[i] == res_final[i]:\n",
    "        #print(\" test\", test_y[i], \"----- res\", res_final[i])\n",
    "        #print(\"correct\")\n",
    "        \n",
    "        ###### ALL CASES\n",
    "        all_text.append(test_x[i])\n",
    "        all_sentiment.append(cat_dict[test_y[i]]) # need to be updated for dict\n",
    "        all_categories.append(test_com[i])\n",
    "        cases +=1\n",
    "        ######\n",
    "        continue\n",
    "    else:\n",
    "        ##################  for the csv set\n",
    "        print(\"--- wrong, sentence: \\n \",test_x[i], \"\\n---- original sentiment \", test_y[i], \"\\n result raw: \", result[i])\n",
    "        # for testing manually \n",
    "        #print(\"--- wrong, sentence: \\n \",Train[i], \"\\n---- original sentiment \", Labels[i], \"\\n result raw: \", result[i])\n",
    "        fault_counter += 1\n",
    "        wrongly_classified_text.append(test_x[i])\n",
    "        wrongly_classified_original_sentiment.append(test_y[i])\n",
    "        ###### ALL CASES\n",
    "        all_text.append(test_x[i])\n",
    "        all_sentiment.append(cat_dict[test_y[i]]) # need to be updated for dict\n",
    "        all_categories.append(test_com[i])\n",
    "        cases +=1\n",
    "        ######\n",
    "print(fault_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07ec96",
   "metadata": {},
   "source": [
    "# Write to JSON, save and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f718434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"reviewText\",\"sentiment\",\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "85ff7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_raw_data = []\n",
    "for i in range(cases):\n",
    "    temp_data = []\n",
    "    def_dict = dict()\n",
    "    for c in keys:\n",
    "        if c ==  \"reviewText\":\n",
    "            def_dict[c] = str(all_text[i])\n",
    "        if c ==  \"sentiment\":\n",
    "            def_dict[c] = str(all_sentiment[i])\n",
    "        if c ==  \"category\":\n",
    "            def_dict[c] = str(all_categories[i])   \n",
    "    json_raw_data.append(def_dict) # ok this is very good, itsa opening with json.load\n",
    "    \n",
    "outFile = open('group16-phase2.json', 'w')\n",
    "for instance in json_raw_data:\n",
    "      outFile.write(json.dumps(instance) + '\\n')\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643ccec",
   "metadata": {},
   "source": [
    "## Check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e0855fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too little instances(43), please generate more\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inputPath = 'group16-phase2.json'\n",
    "\n",
    "for lineIdx, line in enumerate(open(inputPath)):\n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "        #print(data)\n",
    "    except ValueError as e:\n",
    "        print('error, instance ' + str(lineIdx+1) + ' is not in valid json format')\n",
    "        continue\n",
    "    if 'reviewText' not in data:\n",
    "        print(\"error, instance \" + str(lineIdx+1) + ' does not contain key \"reviewText\"')\n",
    "        continue\n",
    "    if 'sentiment' not in data:\n",
    "        print(\"error, instance \" + str(lineIdx+1) + ' does not contain key \"sentiment\"')\n",
    "        continue\n",
    "    if data['sentiment'] not in ['positive', 'negative']:\n",
    "        print(\"error, instance \" + str(lineIdx+1) + ': sentiment is not positive/negative')\n",
    "        continue\n",
    "        \n",
    "if lineIdx+1 < 100:\n",
    "    print('Too little instances(' + str(lineIdx) + '), please generate more')\n",
    "if lineIdx+1 > 1000:\n",
    "    print('Too many instances(' + str(lineIdx) + '), please generate more')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
