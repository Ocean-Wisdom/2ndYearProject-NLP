{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b29b501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MUSIC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MUSIC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import imports as i\n",
    "import functions as f\n",
    "import preprocessing as pp\n",
    "import neuralnetworks as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73776081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  100000\n",
      "Number of data:  10000\n"
     ]
    }
   ],
   "source": [
    "PATH = {}\n",
    "PATH[\"dataset_classification\"] = \"dataset/classification/\"\n",
    "PATH[\"dataset_labeling\"] = \"dataset/seq_labeling/\"\n",
    "PATH[\"music_reviews_train\"] = PATH[\"dataset_classification\"] + \"music_reviews_train.json.gz\"\n",
    "PATH[\"music_reviews_dev\"] = PATH[\"dataset_classification\"] + \"music_reviews_dev.json.gz\"\n",
    "PATH[\"music_reviews_test\"] = PATH[\"dataset_classification\"] + \"music_reviews_test_masked.json.gz\"\n",
    "train = f.readJson(PATH[\"music_reviews_train\"])\n",
    "test = f.readJson(PATH[\"music_reviews_dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a207328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_idx, train_missing_idx = f.json_divide(train)\n",
    "X_test, y_test, test_idx, test_missing_idx = f.json_divide(test)\n",
    "\n",
    "# convert labels\n",
    "sent_dict = {\"positive\": 1, \"negative\": 0}\n",
    "y_train = pp.sentiment_converter(y_train, sent_dict)\n",
    "y_test = pp.sentiment_converter(y_test, sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0e831b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack\n",
    "end = 1000\n",
    "start = 100\n",
    "X_train = X_train[start:end+start]\n",
    "y_train = y_train[start:end+start]\n",
    "X_test = X_test[start:end+start]\n",
    "y_test = y_test[start:end+start]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e4809",
   "metadata": {},
   "source": [
    "## PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "459e8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplyfy contractions\n",
    "train_set_clean = f.simplify_contraction(X_train)\n",
    "test_set_clean = f.simplify_contraction(X_test)\n",
    "\n",
    "# BASIC PREPROCESSING\n",
    "train_set_clean = pp.basic_preprocess(train_set_clean)\n",
    "test_set_clean = pp.basic_preprocess(test_set_clean)\n",
    "\n",
    "# GRAMMAR CORRECTOR \n",
    "train_set_clean = pp.grammar_corrector(train_set_clean)\n",
    "test_set_clean  = pp.grammar_corrector(test_set_clean)\n",
    "\n",
    "# lemmattize \n",
    "train_set_clean = pp.lemmatize_sentencelist(train_set_clean)\n",
    "test_set_clean = pp.lemmatize_sentencelist(test_set_clean)\n",
    "\n",
    "# REMOVE STOP WORDS\n",
    "train_set_clean = pp.remove_stop_words(train_set_clean)\n",
    "test_set_clean = pp.remove_stop_words(test_set_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85162c",
   "metadata": {},
   "source": [
    "## Neural Network INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0237cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenizer\n",
    "tokenizer = pp.tokenizer_init(train_set_clean, test_set_clean)\n",
    "Train = tokenizer.texts_to_sequences(train_set_clean)\n",
    "Test = tokenizer.texts_to_sequences(test_set_clean)\n",
    "# Sequencer \n",
    "X_train_p = pp.sequence_pad(Train) # there are several attributes which can be defined, basic = first 50 words \n",
    "X_test_p = pp.sequence_pad(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaa781",
   "metadata": {},
   "source": [
    "# Train RNN with Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "076333e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 5s 115ms/step - loss: 1.0422 - accuracy: 0.5089 - val_loss: 0.7062 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.5511\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.6636 - accuracy: 0.5511 - val_loss: 0.6794 - val_accuracy: 0.5889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.6833\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.6277 - accuracy: 0.6833 - val_loss: 0.6797 - val_accuracy: 0.5900 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.6922Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.6170 - accuracy: 0.6922 - val_loss: 0.6796 - val_accuracy: 0.5900 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "# TRAIN \n",
    "history, model = nn.RNN_train(X_train_p, y_train, X_test_p, y_test, tokenizer)\n",
    "# model is the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1b22f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5966666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy score\n",
    "result = i.np.round(model.predict(X_test)) # use model from the previous step\n",
    "print(i.accuracy_score(y_test, result))\n",
    "# plotting \n",
    "f.plot_model_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3318b",
   "metadata": {},
   "source": [
    "# POS-tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.tag.html\n",
    "from nltk import pos_tag, word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#only works for english\n",
    "def pos_tag_stringlist(strlist, shouldTokenize):\n",
    "    pos_tagged_strlist = []\n",
    "    if shouldTokenize: \n",
    "        for str in strlist: pos_tagged_strlist.append(pos_tag(word_tokenize(str)))\n",
    "    else: \n",
    "        for str in strlist: pos_tagged_strlist.append(pos_tag(str))\n",
    "    return pos_tagged_strlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb94791",
   "metadata": {},
   "source": [
    "# STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two model\n",
    "### baseline, Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ad337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG the results in pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7999e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS ORDER for Preprocessing\n",
    "# 1. Basic preprocessing - Should be the first step\n",
    "# 2. Grammar Correction\n",
    "# 3. Simplify Contractions\n",
    "# 4. Lemmatize \n",
    "# 5. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee20890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 2. Define the technical parameters of the basic NN\n",
    "## post tagging \n",
    "## 10k same sentence \n",
    "## first 50 word\n",
    "## \n",
    "#### BASE RNN vs Hugging Face \n",
    "# simple pandas dataframe - Columns are preproc methods, 1,0,1, accuracy, etc  \n",
    "# 4. Best vs Worst Accuracy settings test on bigger corpus # Bigger test, Train? Dev set ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0581a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5962aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_list, test_list, y_train, y_test):\n",
    "    simp_contr = [0, 1]\n",
    "    gram_cor = [0, 1]\n",
    "    simp_neg = [0, 1]\n",
    "    lemma = [0, 1]\n",
    "    rem_stop = [0, 1]\n",
    "    list_of_data = []\n",
    "    for z in simp_contr:\n",
    "        for x in gram_cor:\n",
    "            for c in simp_neg:\n",
    "                for v in lemma:\n",
    "                    for b in rem_stop:\n",
    "                        train = train_list\n",
    "                        test = test_list\n",
    "                        if z == 1: # contractions\n",
    "                            train = f.simplify_contraction(train)\n",
    "                            test = f.simplify_contraction(test)\n",
    "                        #train = pp.basic_preprocess(train)\n",
    "                        #test = pp.basic_preprocess(test)\n",
    "                        if x == 1: # grammar correction \n",
    "                            train = train #pp.grammar_corrector(train)\n",
    "                            test = test #pp.grammar_corrector(test)\n",
    "                        if c == 1: # Simnplyfy Negotiation \n",
    "                            train = f.simplify_negation(train)\n",
    "                            test = f.simplify_negation(test)\n",
    "                        if v == 1: # Lemmatize \n",
    "                            train = f.lemmatize_sentencelist(train)\n",
    "                            test = f.lemmatize_sentencelist(test)\n",
    "                        if b == 1: # Remove stop words\n",
    "                            train = pp.remove_stop_words(train)\n",
    "                            test = pp.remove_stop_words(test)\n",
    "                        list_of_data.append([[z, x, c, v, b], train, test])\n",
    "    return list_of_data, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ee15bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets, y_train, y_test = grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['c', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0e21136a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'imports' has no attribute 'pd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1840/1854530574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Running ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Model Name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Simplify Contractions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Basic Preprocessing\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Grammar Correction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lemmatize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Remove Stop Words\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No. of Sentences\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Train Accuracy STOP\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Test Accuracy STOP\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Train Loss STOP\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Test Loss STOP\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'imports' has no attribute 'pd'"
     ]
    }
   ],
   "source": [
    "columns = [\"Running ID\", \"Model Name\", \"Simplify Contractions\", \"Basic Preprocessing\", \"Grammar Correction\", \"Lemmatize\", \"Remove Stop Words\", \"No. of Sentences\", \"Train Accuracy STOP\", \"Test Accuracy STOP\", \"Train Loss STOP\", \"Test Loss STOP\"]\n",
    "results = i.pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0f5eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Combination\n",
      ":  [0, 0, 0, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 135ms/step - loss: 1.0902 - accuracy: 0.5130 - val_loss: 0.7706 - val_accuracy: 0.5820 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.5980\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 131ms/step - loss: 0.6441 - accuracy: 0.5980 - val_loss: 0.6673 - val_accuracy: 0.6010 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.7960\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 2s 126ms/step - loss: 0.5909 - accuracy: 0.7960 - val_loss: 0.6606 - val_accuracy: 0.6140 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5777 - accuracy: 0.7950\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 2s 125ms/step - loss: 0.5777 - accuracy: 0.7950 - val_loss: 0.6591 - val_accuracy: 0.6160 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.7960Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 2s 125ms/step - loss: 0.5743 - accuracy: 0.7960 - val_loss: 0.6589 - val_accuracy: 0.6160 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 0, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 167ms/step - loss: 2.0589 - accuracy: 0.5000 - val_loss: 0.7323 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.5390\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.6673 - accuracy: 0.5390 - val_loss: 0.6886 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.6420Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.6102 - accuracy: 0.6420 - val_loss: 0.6824 - val_accuracy: 0.5740 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 0, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 181ms/step - loss: 0.9703 - accuracy: 0.5320 - val_loss: 0.6774 - val_accuracy: 0.5910 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.6800\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.6275 - accuracy: 0.6800 - val_loss: 0.6744 - val_accuracy: 0.6090 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.7810\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.5731 - accuracy: 0.7810 - val_loss: 0.6538 - val_accuracy: 0.6320 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7890\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.5502 - accuracy: 0.7890 - val_loss: 0.6524 - val_accuracy: 0.6360 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7910Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.5452 - accuracy: 0.7910 - val_loss: 0.6520 - val_accuracy: 0.6330 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 0, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 169ms/step - loss: 1.1072 - accuracy: 0.5230 - val_loss: 0.7276 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.5370\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.6842 - accuracy: 0.5370 - val_loss: 0.6913 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.5910Restoring model weights from the end of the best epoch: 2.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.6219 - accuracy: 0.5910 - val_loss: 0.6879 - val_accuracy: 0.5720 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 1, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 142ms/step - loss: 1.4800 - accuracy: 0.5230 - val_loss: 0.7548 - val_accuracy: 0.5980 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.5710Restoring model weights from the end of the best epoch: 1.\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 0.6551 - accuracy: 0.5710 - val_loss: 0.6715 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 1, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 173ms/step - loss: 0.9128 - accuracy: 0.5520 - val_loss: 0.6937 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.6850\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.6301 - accuracy: 0.6850 - val_loss: 0.6759 - val_accuracy: 0.5910 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.7340\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.5337 - accuracy: 0.7340 - val_loss: 0.6699 - val_accuracy: 0.6350 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8730Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.4650 - accuracy: 0.8730 - val_loss: 0.6570 - val_accuracy: 0.6020 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 1, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 159ms/step - loss: 0.9678 - accuracy: 0.5310 - val_loss: 0.6792 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.6110\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 135ms/step - loss: 0.6348 - accuracy: 0.6110 - val_loss: 0.6621 - val_accuracy: 0.6210 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.7800\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.5812 - accuracy: 0.7800 - val_loss: 0.6584 - val_accuracy: 0.6220 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7900Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.5634 - accuracy: 0.7900 - val_loss: 0.6575 - val_accuracy: 0.6210 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [0, 0, 1, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 160ms/step - loss: 1.1855 - accuracy: 0.4940 - val_loss: 0.7745 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5450\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 144ms/step - loss: 0.6914 - accuracy: 0.5450 - val_loss: 0.6947 - val_accuracy: 0.5750 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.6040\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.6145 - accuracy: 0.6040 - val_loss: 0.6911 - val_accuracy: 0.5760 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.6670Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.5980 - accuracy: 0.6670 - val_loss: 0.6894 - val_accuracy: 0.5760 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 0, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 144ms/step - loss: 1.0918 - accuracy: 0.5200 - val_loss: 0.7669 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6567 - accuracy: 0.5680\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 2s 122ms/step - loss: 0.6567 - accuracy: 0.5680 - val_loss: 0.6796 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.6600\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 0.6014 - accuracy: 0.6600 - val_loss: 0.6754 - val_accuracy: 0.5940 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.7030\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 0.5910 - accuracy: 0.7030 - val_loss: 0.6747 - val_accuracy: 0.5950 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7130Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 0.5884 - accuracy: 0.7130 - val_loss: 0.6745 - val_accuracy: 0.5950 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 0, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 193ms/step - loss: 1.5734 - accuracy: 0.5020 - val_loss: 0.7313 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.5370\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.6798 - accuracy: 0.5370 - val_loss: 0.6882 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6270Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.6150 - accuracy: 0.6270 - val_loss: 0.6839 - val_accuracy: 0.5730 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 0, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 156ms/step - loss: 1.0609 - accuracy: 0.5220 - val_loss: 0.7181 - val_accuracy: 0.5860 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.5900\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 135ms/step - loss: 0.6426 - accuracy: 0.5900 - val_loss: 0.6642 - val_accuracy: 0.6240 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7860Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.5838 - accuracy: 0.7860 - val_loss: 0.6610 - val_accuracy: 0.6240 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 0, 1, 1]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x000001ED0E056160>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\music\\appdata\\local\\programs\\python\\python39\\lib\\weakref.py\", line 368, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 14s 191ms/step - loss: 1.6346 - accuracy: 0.5170 - val_loss: 0.7025 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.5450\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.6599 - accuracy: 0.5450 - val_loss: 0.6778 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7050\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.6075 - accuracy: 0.7050 - val_loss: 0.6746 - val_accuracy: 0.5820 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.7240\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.5928 - accuracy: 0.7240 - val_loss: 0.6741 - val_accuracy: 0.5850 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.7240\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.5890 - accuracy: 0.7240 - val_loss: 0.6739 - val_accuracy: 0.5860 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7240Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.5882 - accuracy: 0.7240 - val_loss: 0.6739 - val_accuracy: 0.5860 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 1, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 168ms/step - loss: 1.0724 - accuracy: 0.5360 - val_loss: 0.7375 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.5570Restoring model weights from the end of the best epoch: 1.\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.6554 - accuracy: 0.5570 - val_loss: 0.6743 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 1, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 173ms/step - loss: 1.0177 - accuracy: 0.5210 - val_loss: 0.7191 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.5710\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.6652 - accuracy: 0.5710 - val_loss: 0.6789 - val_accuracy: 0.5800 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7190\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.5843 - accuracy: 0.7190 - val_loss: 0.6738 - val_accuracy: 0.5870 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5456 - accuracy: 0.7270\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.5456 - accuracy: 0.7270 - val_loss: 0.6707 - val_accuracy: 0.5900 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7280\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.5321 - accuracy: 0.7280 - val_loss: 0.6697 - val_accuracy: 0.5930 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7280Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.5288 - accuracy: 0.7280 - val_loss: 0.6696 - val_accuracy: 0.5930 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 1, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 203ms/step - loss: 1.1648 - accuracy: 0.4950 - val_loss: 0.7244 - val_accuracy: 0.5920 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.5570Restoring model weights from the end of the best epoch: 1.\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.6828 - accuracy: 0.5570 - val_loss: 0.7075 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 1, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 198ms/step - loss: 2.4253 - accuracy: 0.4920 - val_loss: 0.7616 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.5510\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 177ms/step - loss: 0.6662 - accuracy: 0.5510 - val_loss: 0.6925 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.5620\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 178ms/step - loss: 0.6196 - accuracy: 0.5620 - val_loss: 0.6865 - val_accuracy: 0.5760 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.5830Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.6071 - accuracy: 0.5830 - val_loss: 0.6854 - val_accuracy: 0.5750 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 0, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 165ms/step - loss: 1.1235 - accuracy: 0.5120 - val_loss: 0.7667 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.5610\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.6617 - accuracy: 0.5610 - val_loss: 0.6824 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.5950\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.6093 - accuracy: 0.5950 - val_loss: 0.6796 - val_accuracy: 0.5890 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.6360\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 138ms/step - loss: 0.6001 - accuracy: 0.6360 - val_loss: 0.6792 - val_accuracy: 0.5910 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.6520Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 0.5980 - accuracy: 0.6520 - val_loss: 0.6791 - val_accuracy: 0.5910 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 0, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 185ms/step - loss: 1.4718 - accuracy: 0.5150 - val_loss: 0.7068 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.5720\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.6613 - accuracy: 0.5720 - val_loss: 0.6786 - val_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.7010\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.6026 - accuracy: 0.7010 - val_loss: 0.6755 - val_accuracy: 0.5890 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.7120Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.5835 - accuracy: 0.7120 - val_loss: 0.6756 - val_accuracy: 0.5890 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 0, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 183ms/step - loss: 1.5004 - accuracy: 0.5230 - val_loss: 0.7185 - val_accuracy: 0.5890 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.5600\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 0.6451 - accuracy: 0.5600 - val_loss: 0.6698 - val_accuracy: 0.5910 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.6820\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.5971 - accuracy: 0.6820 - val_loss: 0.6662 - val_accuracy: 0.6080 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.7600Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.5870 - accuracy: 0.7600 - val_loss: 0.6658 - val_accuracy: 0.6060 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 0, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 203ms/step - loss: 1.7955 - accuracy: 0.5140 - val_loss: 0.7995 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.5410\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.6894 - accuracy: 0.5410 - val_loss: 0.6937 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.5470Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6260 - accuracy: 0.5470 - val_loss: 0.6906 - val_accuracy: 0.5730 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 1, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 182ms/step - loss: 1.1011 - accuracy: 0.5130 - val_loss: 0.7125 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.5690\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.6582 - accuracy: 0.5690 - val_loss: 0.6686 - val_accuracy: 0.5930 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.7430\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.5961 - accuracy: 0.7430 - val_loss: 0.6634 - val_accuracy: 0.6080 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.7760Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.5865 - accuracy: 0.7760 - val_loss: 0.6629 - val_accuracy: 0.6080 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 1, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 193ms/step - loss: 1.7790 - accuracy: 0.5090 - val_loss: 0.7320 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6720 - accuracy: 0.5410\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6720 - accuracy: 0.5410 - val_loss: 0.6866 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6400Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.6139 - accuracy: 0.6400 - val_loss: 0.6820 - val_accuracy: 0.5730 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 1, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 197ms/step - loss: 2.5472 - accuracy: 0.4680 - val_loss: 0.7502 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5640\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6947 - accuracy: 0.5640 - val_loss: 0.6970 - val_accuracy: 0.5920 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.5600Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6325 - accuracy: 0.5600 - val_loss: 0.6954 - val_accuracy: 0.5910 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [1, 0, 1, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 272ms/step - loss: 1.3420 - accuracy: 0.4890 - val_loss: 0.7523 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7099 - accuracy: 0.5370Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 212ms/step - loss: 0.7099 - accuracy: 0.5370 - val_loss: 0.7142 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 0, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 190ms/step - loss: 1.4825 - accuracy: 0.5220 - val_loss: 0.7719 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.5620Restoring model weights from the end of the best epoch: 1.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.6623 - accuracy: 0.5620 - val_loss: 0.6744 - val_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 0, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 251ms/step - loss: 1.0237 - accuracy: 0.5230 - val_loss: 0.7224 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6722 - accuracy: 0.5300Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.6722 - accuracy: 0.5300 - val_loss: 0.6837 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 0, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 225ms/step - loss: 1.0383 - accuracy: 0.5450 - val_loss: 0.6747 - val_accuracy: 0.5890 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.6620\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 223ms/step - loss: 0.6254 - accuracy: 0.6620 - val_loss: 0.6559 - val_accuracy: 0.6350 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7820\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.5549 - accuracy: 0.7820 - val_loss: 0.6492 - val_accuracy: 0.6400 - lr: 2.0000e-04\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8010\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.5271 - accuracy: 0.8010 - val_loss: 0.6461 - val_accuracy: 0.6420 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8000Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 217ms/step - loss: 0.5180 - accuracy: 0.8000 - val_loss: 0.6451 - val_accuracy: 0.6420 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 0, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 9s 298ms/step - loss: 1.0819 - accuracy: 0.5030 - val_loss: 0.7720 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.5400\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 0.6766 - accuracy: 0.5400 - val_loss: 0.6912 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.5860Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.6119 - accuracy: 0.5860 - val_loss: 0.6852 - val_accuracy: 0.5730 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 1, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 216ms/step - loss: 1.5719 - accuracy: 0.5140 - val_loss: 0.7403 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.5720Restoring model weights from the end of the best epoch: 1.\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.6560 - accuracy: 0.5720 - val_loss: 0.6709 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 2: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 1, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 254ms/step - loss: 2.6191 - accuracy: 0.4950 - val_loss: 0.8093 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.5460\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 218ms/step - loss: 0.6798 - accuracy: 0.5460 - val_loss: 0.7027 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.5490Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.6335 - accuracy: 0.5490 - val_loss: 0.6947 - val_accuracy: 0.5760 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 1, 1, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 18s 208ms/step - loss: 1.6477 - accuracy: 0.4790 - val_loss: 0.7081 - val_accuracy: 0.5820 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.5870\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.6479 - accuracy: 0.5870 - val_loss: 0.6777 - val_accuracy: 0.5950 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.6870\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.5801 - accuracy: 0.6870 - val_loss: 0.6696 - val_accuracy: 0.6020 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7400Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.5670 - accuracy: 0.7400 - val_loss: 0.6683 - val_accuracy: 0.6010 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "##### Combination\n",
      ":  [1, 1, 1, 1, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 213ms/step - loss: 1.0761 - accuracy: 0.5130 - val_loss: 0.7148 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.5410Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.6819 - accuracy: 0.5410 - val_loss: 0.6839 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'        if result[1] > best_result[1]:\\n            best_result = [data_set[0], result]\\n    return best_result'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = [[], 0]\n",
    "for data_set in data_sets:\n",
    "    # Tokenizer\n",
    "    print(\"##### Combination\\n: \", data_set[0])\n",
    "    tokenizer = pp.tokenizer_init(data_set[1], data_set[2])\n",
    "    Train = tokenizer.texts_to_sequences(data_set[1])\n",
    "    Test = tokenizer.texts_to_sequences(data_set[2])\n",
    "        # Sequencer \n",
    "    X_train_p = pp.sequence_pad(Train) # there are several attributes which can be defined, basic = first 50 words \n",
    "    X_test_p = pp.sequence_pad(Test)\n",
    "        \n",
    "        # TRAIN\n",
    "    #print(\"shapes: \", X_train_p.shape, X_test_p.shape)\n",
    "    history, model = nn.RNN_train(X_train_p, y_train, X_test_p, y_test, tokenizer)\n",
    "        \n",
    "        # accuracy score\n",
    "    #result = i.np.round(model.predict(data_set[1])) # use model from the previous step\n",
    "    #print(\"#### Accuracy: \", result)\n",
    "'''        if result[1] > best_result[1]:\n",
    "            best_result = [data_set[0], result]\n",
    "    return best_result'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f5ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
