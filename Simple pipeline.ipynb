{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2b29b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imports as ii\n",
    "import functions as f\n",
    "import preprocessing as pp\n",
    "import neuralnetworks as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "73776081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  100000\n",
      "Number of data:  10000\n"
     ]
    }
   ],
   "source": [
    "PATH = {}\n",
    "PATH[\"dataset_classification\"] = \"dataset/classification/\"\n",
    "PATH[\"dataset_labeling\"] = \"dataset/seq_labeling/\"\n",
    "PATH[\"music_reviews_train\"] = PATH[\"dataset_classification\"] + \"music_reviews_train.json.gz\"\n",
    "PATH[\"music_reviews_dev\"] = PATH[\"dataset_classification\"] + \"music_reviews_dev.json.gz\"\n",
    "PATH[\"music_reviews_test\"] = PATH[\"dataset_classification\"] + \"music_reviews_test_masked.json.gz\"\n",
    "train = f.readJson(PATH[\"music_reviews_train\"])\n",
    "test = f.readJson(PATH[\"music_reviews_dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a207328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_idx, train_missing_idx = f.json_divide(train)\n",
    "X_test, y_test, test_idx, test_missing_idx = f.json_divide(test)\n",
    "\n",
    "# convert labels\n",
    "sent_dict = {\"positive\": 1, \"negative\": 0}\n",
    "y_train = pp.sentiment_converter(y_train, sent_dict)\n",
    "y_test = pp.sentiment_converter(y_test, sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1aa43ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack\n",
    "end = 30000\n",
    "start = 100\n",
    "X_train = X_train[start:end+start]\n",
    "y_train = y_train[start:end+start]\n",
    "X_test = X_test[start:end+start]\n",
    "y_test = y_test[start:end+start]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e4809",
   "metadata": {},
   "source": [
    "## PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "459e8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplyfy contractions\n",
    "train_set_clean = f.simplify_contraction(X_train)\n",
    "test_set_clean = f.simplify_contraction(X_test)\n",
    "\n",
    "# BASIC PREPROCESSING\n",
    "train_set_clean = pp.basic_preprocess(train_set_clean)\n",
    "test_set_clean = pp.basic_preprocess(test_set_clean)\n",
    "\n",
    "# GRAMMAR CORRECTOR \n",
    "train_set_clean = pp.grammar_corrector(train_set_clean)\n",
    "test_set_clean  = pp.grammar_corrector(test_set_clean)\n",
    "\n",
    "# lemmattize \n",
    "train_set_clean = pp.lemmatize_sentencelist(train_set_clean)\n",
    "test_set_clean = pp.lemmatize_sentencelist(test_set_clean)\n",
    "\n",
    "# REMOVE STOP WORDS\n",
    "train_set_clean = pp.remove_stop_words(train_set_clean)\n",
    "test_set_clean = pp.remove_stop_words(test_set_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85162c",
   "metadata": {},
   "source": [
    "## Neural Network INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0237cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = pp.tokenizer_init(train_set_clean, test_set_clean)\n",
    "Train = tokenizer.texts_to_sequences(train_set_clean)\n",
    "Test = tokenizer.texts_to_sequences(test_set_clean)\n",
    "# Sequencer \n",
    "X_train_p = pp.sequence_pad(Train) # there are several attributes which can be defined, basic = first 50 words \n",
    "X_test_p = pp.sequence_pad(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaa781",
   "metadata": {},
   "source": [
    "# Train RNN with Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "076333e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 5s 115ms/step - loss: 1.0422 - accuracy: 0.5089 - val_loss: 0.7062 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.5511\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.6636 - accuracy: 0.5511 - val_loss: 0.6794 - val_accuracy: 0.5889 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.6833\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.6277 - accuracy: 0.6833 - val_loss: 0.6797 - val_accuracy: 0.5900 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.6922Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.6170 - accuracy: 0.6922 - val_loss: 0.6796 - val_accuracy: 0.5900 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "# TRAIN \n",
    "history, model = nn.RNN_train(X_train_p, y_train, X_test_p, y_test, tokenizer)\n",
    "# model is the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1b22f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5966666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy score\n",
    "result = ii.np.round(model.predict(X_test)) # use model from the previous step\n",
    "print(i.accuracy_score(y_test, result))\n",
    "# plotting \n",
    "f.plot_model_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3318b",
   "metadata": {},
   "source": [
    "# POS-tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.tag.html\n",
    "from nltk import pos_tag, word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#only works for english\n",
    "def pos_tag_stringlist(strlist, shouldTokenize):\n",
    "    pos_tagged_strlist = []\n",
    "    if shouldTokenize: \n",
    "        for str in strlist: pos_tagged_strlist.append(pos_tag(word_tokenize(str)))\n",
    "    else: \n",
    "        for str in strlist: pos_tagged_strlist.append(pos_tag(str))\n",
    "    return pos_tagged_strlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb94791",
   "metadata": {},
   "source": [
    "# STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two model\n",
    "### baseline, Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ad337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG the results in pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7999e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS ORDER for Preprocessing\n",
    "# 1. Basic preprocessing - Should be the first step\n",
    "# 2. Grammar Correction\n",
    "# 3. Simplify Contractions\n",
    "# 4. Lemmatize \n",
    "# 5. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee20890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 2. Define the technical parameters of the basic NN\n",
    "## post tagging \n",
    "## 10k same sentence \n",
    "## first 50 word\n",
    "## \n",
    "#### BASE RNN vs Hugging Face \n",
    "# simple pandas dataframe - Columns are preproc methods, 1,0,1, accuracy, etc  \n",
    "# 4. Best vs Worst Accuracy settings test on bigger corpus # Bigger test, Train? Dev set ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0581a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5962aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_list, test_list, y_train, y_test):\n",
    "    simp_contr = [0, 1]\n",
    "    gram_cor = [0, 1]\n",
    "    simp_neg = [0, 1]\n",
    "    lemma = [0, 1]\n",
    "    rem_stop = [0, 1]\n",
    "    basic_preprocessing = 1\n",
    "    list_of_data = []\n",
    "    for z in simp_contr:\n",
    "        for x in gram_cor:\n",
    "            for c in simp_neg:\n",
    "                for v in lemma:\n",
    "                    for b in rem_stop:\n",
    "                        train = train_list\n",
    "                        test = test_list\n",
    "                        if z == 1: # contractions\n",
    "                            train = f.simplify_contraction(train)\n",
    "                            test = f.simplify_contraction(test)\n",
    "                        if basic_preprocessing == 1: # basic preprocessing\n",
    "                            train = pp.basic_preprocess(train)\n",
    "                            test = pp.basic_preprocess(test)\n",
    "                        if x == 1: # grammar correction \n",
    "                            train = pp.grammar_corrector(train)\n",
    "                            test = pp.grammar_corrector(test)\n",
    "                        if c == 1: # Simnplyfy Negotiation \n",
    "                            train = f.simplify_negation(train)\n",
    "                            test = f.simplify_negation(test)\n",
    "                        if v == 1: # Lemmatize \n",
    "                            train = f.lemmatize_sentencelist(train)\n",
    "                            test = f.lemmatize_sentencelist(test)\n",
    "                        if b == 1: # Remove stop words\n",
    "                            train = pp.remove_stop_words(train)\n",
    "                            test = pp.remove_stop_words(test)\n",
    "\n",
    "                        list_of_data.append([[z, basic_preprocessing, x, c, v, b], train, test]) #\n",
    "    return list_of_data, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "15385e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets, y_train, y_test = grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "32750cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 182ms/step - loss: 1.2024 - accuracy: 0.5200 - val_loss: 0.7496 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.5850\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6551 - accuracy: 0.5850 - val_loss: 0.6745 - val_accuracy: 0.5920 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6140\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.6177 - accuracy: 0.6140 - val_loss: 0.6722 - val_accuracy: 0.5970 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6370\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.6105 - accuracy: 0.6370 - val_loss: 0.6719 - val_accuracy: 0.5960 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.6580\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.6089 - accuracy: 0.6580 - val_loss: 0.6718 - val_accuracy: 0.5960 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 215ms/step - loss: 1.7598 - accuracy: 0.5110 - val_loss: 0.7172 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.5460\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.6696 - accuracy: 0.5460 - val_loss: 0.6873 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.6430\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 0.6334 - accuracy: 0.6430 - val_loss: 0.6810 - val_accuracy: 0.5840 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.6780\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.6240 - accuracy: 0.6780 - val_loss: 0.6804 - val_accuracy: 0.5870 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.6830\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.6221 - accuracy: 0.6830 - val_loss: 0.6802 - val_accuracy: 0.5870 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6840\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.6217 - accuracy: 0.6840 - val_loss: 0.6802 - val_accuracy: 0.5870 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 235ms/step - loss: 1.0622 - accuracy: 0.5330 - val_loss: 0.6788 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.6410\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6460 - accuracy: 0.6410 - val_loss: 0.6625 - val_accuracy: 0.6180 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.7740\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.6033 - accuracy: 0.7740 - val_loss: 0.6601 - val_accuracy: 0.6220 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7770\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.5914 - accuracy: 0.7770 - val_loss: 0.6590 - val_accuracy: 0.6220 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7780\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.5884 - accuracy: 0.7780 - val_loss: 0.6587 - val_accuracy: 0.6230 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7780\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.5878 - accuracy: 0.7780 - val_loss: 0.6586 - val_accuracy: 0.6220 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7780\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.5876 - accuracy: 0.7780 - val_loss: 0.6586 - val_accuracy: 0.6220 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 222ms/step - loss: 1.0682 - accuracy: 0.5100 - val_loss: 0.7516 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.5440\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6903 - accuracy: 0.5440 - val_loss: 0.6932 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.5540\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.6434 - accuracy: 0.5540 - val_loss: 0.6912 - val_accuracy: 0.5760 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.5610\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6362 - accuracy: 0.5610 - val_loss: 0.6909 - val_accuracy: 0.5760 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5630\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.6346 - accuracy: 0.5630 - val_loss: 0.6909 - val_accuracy: 0.5760 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 1.3829 - accuracy: 0.5190 - val_loss: 0.7535 - val_accuracy: 0.5800 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.5660\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.6501 - accuracy: 0.5660 - val_loss: 0.6703 - val_accuracy: 0.5860 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.6980\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.5992 - accuracy: 0.6980 - val_loss: 0.6660 - val_accuracy: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7630\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.5875 - accuracy: 0.7630 - val_loss: 0.6652 - val_accuracy: 0.6060 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7700\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.5847 - accuracy: 0.7700 - val_loss: 0.6651 - val_accuracy: 0.6070 - lr: 8.0000e-06\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.7700\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 214ms/step - loss: 0.5840 - accuracy: 0.7700 - val_loss: 0.6650 - val_accuracy: 0.6070 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.7700\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.5839 - accuracy: 0.7700 - val_loss: 0.6650 - val_accuracy: 0.6070 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 230ms/step - loss: 1.0389 - accuracy: 0.5080 - val_loss: 0.6970 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.5890\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.6521 - accuracy: 0.5890 - val_loss: 0.6745 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5955 - accuracy: 0.7140\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.5955 - accuracy: 0.7140 - val_loss: 0.6722 - val_accuracy: 0.5980 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7220\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.5782 - accuracy: 0.7220 - val_loss: 0.6724 - val_accuracy: 0.5990 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.7240\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.5741 - accuracy: 0.7240 - val_loss: 0.6721 - val_accuracy: 0.5990 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7240\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.5732 - accuracy: 0.7240 - val_loss: 0.6721 - val_accuracy: 0.5990 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 221ms/step - loss: 1.0608 - accuracy: 0.5320 - val_loss: 0.7351 - val_accuracy: 0.6030 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.6352 - accuracy: 0.6430 - val_loss: 0.6688 - val_accuracy: 0.6020 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.7700\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.5725 - accuracy: 0.7700 - val_loss: 0.6513 - val_accuracy: 0.6370 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.7950\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 0.4855 - accuracy: 0.7950 - val_loss: 0.6171 - val_accuracy: 0.6550 - lr: 2.0000e-04\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.8260\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.4376 - accuracy: 0.8260 - val_loss: 0.6065 - val_accuracy: 0.6540 - lr: 4.0000e-05\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.8250\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.4199 - accuracy: 0.8250 - val_loss: 0.6041 - val_accuracy: 0.6540 - lr: 8.0000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 217ms/step - loss: 8.2061 - accuracy: 0.4680 - val_loss: 9.0390 - val_accuracy: 0.4140 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.2061 - accuracy: 0.4680\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 8.2061 - accuracy: 0.4680 - val_loss: 9.0390 - val_accuracy: 0.4140 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.2061 - accuracy: 0.4680\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 8.2061 - accuracy: 0.4680 - val_loss: 9.0390 - val_accuracy: 0.4140 - lr: 2.0000e-04\n",
      "Epoch 3: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 218ms/step - loss: 1.1214 - accuracy: 0.5010 - val_loss: 0.7208 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.5880\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.6512 - accuracy: 0.5880 - val_loss: 0.6702 - val_accuracy: 0.5910 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.6380\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.6210 - accuracy: 0.6380 - val_loss: 0.6673 - val_accuracy: 0.5970 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.6930\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.6127 - accuracy: 0.6930 - val_loss: 0.6669 - val_accuracy: 0.6000 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.7010\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6110 - accuracy: 0.7010 - val_loss: 0.6668 - val_accuracy: 0.6000 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7010\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6106 - accuracy: 0.7010 - val_loss: 0.6668 - val_accuracy: 0.6000 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 219ms/step - loss: 1.2357 - accuracy: 0.4840 - val_loss: 0.7062 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.5340\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6821 - accuracy: 0.5340 - val_loss: 0.6892 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.6220\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.6425 - accuracy: 0.6220 - val_loss: 0.6848 - val_accuracy: 0.5750 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.6480\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.6354 - accuracy: 0.6480 - val_loss: 0.6844 - val_accuracy: 0.5770 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.6550\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6339 - accuracy: 0.6550 - val_loss: 0.6843 - val_accuracy: 0.5780 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6550\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6335 - accuracy: 0.6550 - val_loss: 0.6843 - val_accuracy: 0.5780 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6550\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.6335 - accuracy: 0.6550 - val_loss: 0.6843 - val_accuracy: 0.5780 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 214ms/step - loss: 1.5412 - accuracy: 0.5430 - val_loss: 0.6849 - val_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6504 - accuracy: 0.6090\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.6504 - accuracy: 0.6090 - val_loss: 0.6644 - val_accuracy: 0.6120 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.7640\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.6149 - accuracy: 0.7640 - val_loss: 0.6618 - val_accuracy: 0.6170 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.7660\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.6045 - accuracy: 0.7660 - val_loss: 0.6612 - val_accuracy: 0.6160 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.7700\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.6021 - accuracy: 0.7700 - val_loss: 0.6611 - val_accuracy: 0.6160 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 215ms/step - loss: 1.7295 - accuracy: 0.4980 - val_loss: 0.7336 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.5350\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.6861 - accuracy: 0.5350 - val_loss: 0.6898 - val_accuracy: 0.5710 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.5630\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.6455 - accuracy: 0.5630 - val_loss: 0.6868 - val_accuracy: 0.5730 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.6060\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.6367 - accuracy: 0.6060 - val_loss: 0.6861 - val_accuracy: 0.5730 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.6160\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.6344 - accuracy: 0.6160 - val_loss: 0.6859 - val_accuracy: 0.5740 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.6170\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.6339 - accuracy: 0.6170 - val_loss: 0.6859 - val_accuracy: 0.5740 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.6170\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 4s 224ms/step - loss: 0.6338 - accuracy: 0.6170 - val_loss: 0.6859 - val_accuracy: 0.5740 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 245ms/step - loss: 1.9313 - accuracy: 0.4990 - val_loss: 0.6874 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.5820\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 5s 227ms/step - loss: 0.6499 - accuracy: 0.5820 - val_loss: 0.6654 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.7590\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 214ms/step - loss: 0.6041 - accuracy: 0.7590 - val_loss: 0.6631 - val_accuracy: 0.6080 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.7720\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.5949 - accuracy: 0.7720 - val_loss: 0.6625 - val_accuracy: 0.6080 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.7720\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.5927 - accuracy: 0.7720 - val_loss: 0.6624 - val_accuracy: 0.6080 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 200ms/step - loss: 0.8732 - accuracy: 0.5370 - val_loss: 0.6943 - val_accuracy: 0.5710 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.5950\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.6623 - accuracy: 0.5950 - val_loss: 0.6780 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.6800\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.6230 - accuracy: 0.6800 - val_loss: 0.6782 - val_accuracy: 0.5840 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.6920\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.6132 - accuracy: 0.6920 - val_loss: 0.6780 - val_accuracy: 0.5840 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.6920\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6107 - accuracy: 0.6920 - val_loss: 0.6778 - val_accuracy: 0.5840 - lr: 8.0000e-06\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 206ms/step - loss: 1.0012 - accuracy: 0.5400 - val_loss: 0.6716 - val_accuracy: 0.5920 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.6690\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6358 - accuracy: 0.6690 - val_loss: 0.6578 - val_accuracy: 0.6260 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.7690\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.5909 - accuracy: 0.7690 - val_loss: 0.6532 - val_accuracy: 0.6360 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7780\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.5769 - accuracy: 0.7780 - val_loss: 0.6521 - val_accuracy: 0.6360 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5737 - accuracy: 0.7810\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 172ms/step - loss: 0.5737 - accuracy: 0.7810 - val_loss: 0.6518 - val_accuracy: 0.6370 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.7820\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.5730 - accuracy: 0.7820 - val_loss: 0.6517 - val_accuracy: 0.6370 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.7820\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.5728 - accuracy: 0.7820 - val_loss: 0.6517 - val_accuracy: 0.6370 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 190ms/step - loss: 1.0036 - accuracy: 0.5200 - val_loss: 0.7364 - val_accuracy: 0.5710 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.5390\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.6740 - accuracy: 0.5390 - val_loss: 0.6879 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.5910\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.6351 - accuracy: 0.5910 - val_loss: 0.6818 - val_accuracy: 0.5760 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.6680\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.6227 - accuracy: 0.6680 - val_loss: 0.6809 - val_accuracy: 0.5780 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.6800\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.6200 - accuracy: 0.6800 - val_loss: 0.6807 - val_accuracy: 0.5780 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.6840\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.6195 - accuracy: 0.6840 - val_loss: 0.6807 - val_accuracy: 0.5780 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 201ms/step - loss: 0.8661 - accuracy: 0.5300 - val_loss: 0.6862 - val_accuracy: 0.5820 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6230\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.6475 - accuracy: 0.6230 - val_loss: 0.6646 - val_accuracy: 0.6180 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.7610\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.5948 - accuracy: 0.7610 - val_loss: 0.6598 - val_accuracy: 0.6300 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.7750\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.5823 - accuracy: 0.7750 - val_loss: 0.6591 - val_accuracy: 0.6300 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.7750\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.5790 - accuracy: 0.7750 - val_loss: 0.6588 - val_accuracy: 0.6320 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.7750\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.5783 - accuracy: 0.7750 - val_loss: 0.6587 - val_accuracy: 0.6320 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7750\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.5781 - accuracy: 0.7750 - val_loss: 0.6587 - val_accuracy: 0.6320 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 198ms/step - loss: 1.4779 - accuracy: 0.5220 - val_loss: 0.6926 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6649 - accuracy: 0.5710\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.6649 - accuracy: 0.5710 - val_loss: 0.6812 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.6820\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6270 - accuracy: 0.6820 - val_loss: 0.6796 - val_accuracy: 0.5860 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.6920\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6192 - accuracy: 0.6920 - val_loss: 0.6793 - val_accuracy: 0.5850 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.6970\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 177ms/step - loss: 0.6173 - accuracy: 0.6970 - val_loss: 0.6792 - val_accuracy: 0.5870 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.6970\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.6169 - accuracy: 0.6970 - val_loss: 0.6792 - val_accuracy: 0.5870 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.6970\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.6168 - accuracy: 0.6970 - val_loss: 0.6792 - val_accuracy: 0.5870 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 1.0320 - accuracy: 0.5310 - val_loss: 0.6873 - val_accuracy: 0.5890 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.5950\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.6449 - accuracy: 0.5950 - val_loss: 0.6660 - val_accuracy: 0.6130 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.7540\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.6095 - accuracy: 0.7540 - val_loss: 0.6634 - val_accuracy: 0.6200 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.7690\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.6006 - accuracy: 0.7690 - val_loss: 0.6627 - val_accuracy: 0.6210 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.7710\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.5983 - accuracy: 0.7710 - val_loss: 0.6626 - val_accuracy: 0.6210 - lr: 8.0000e-06\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.7720\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.5978 - accuracy: 0.7720 - val_loss: 0.6626 - val_accuracy: 0.6200 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 228ms/step - loss: 0.8834 - accuracy: 0.4990 - val_loss: 0.6878 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.6140\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.6559 - accuracy: 0.6140 - val_loss: 0.6774 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6900\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.6159 - accuracy: 0.6900 - val_loss: 0.6767 - val_accuracy: 0.5910 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.7100\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.6011 - accuracy: 0.7100 - val_loss: 0.6759 - val_accuracy: 0.5910 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.7120\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.5977 - accuracy: 0.7120 - val_loss: 0.6757 - val_accuracy: 0.5920 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7120\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 205ms/step - loss: 0.5970 - accuracy: 0.7120 - val_loss: 0.6757 - val_accuracy: 0.5920 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.7120\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 4s 205ms/step - loss: 0.5968 - accuracy: 0.7120 - val_loss: 0.6756 - val_accuracy: 0.5920 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 235ms/step - loss: 1.3275 - accuracy: 0.5220 - val_loss: 0.7736 - val_accuracy: 0.5810 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.5620\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.6612 - accuracy: 0.5620 - val_loss: 0.6781 - val_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.5780\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.6134 - accuracy: 0.5780 - val_loss: 0.6749 - val_accuracy: 0.5890 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.6120\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 213ms/step - loss: 0.6035 - accuracy: 0.6120 - val_loss: 0.6742 - val_accuracy: 0.5890 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.6280\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.6015 - accuracy: 0.6280 - val_loss: 0.6741 - val_accuracy: 0.5900 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.6270\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.6010 - accuracy: 0.6270 - val_loss: 0.6741 - val_accuracy: 0.5900 - lr: 1.6000e-06\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.6270\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 0.6010 - accuracy: 0.6270 - val_loss: 0.6741 - val_accuracy: 0.5900 - lr: 3.2000e-07\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 6s 239ms/step - loss: 1.0061 - accuracy: 0.5300 - val_loss: 0.7441 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.5460\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 4s 212ms/step - loss: 0.6849 - accuracy: 0.5460 - val_loss: 0.6877 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.5620\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 4s 215ms/step - loss: 0.6354 - accuracy: 0.5620 - val_loss: 0.6855 - val_accuracy: 0.5790 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.5810\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 4s 214ms/step - loss: 0.6275 - accuracy: 0.5810 - val_loss: 0.6852 - val_accuracy: 0.5790 - lr: 4.0000e-05\n",
      "Epoch 4: early stopping\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 263ms/step - loss: 1.0561 - accuracy: 0.5350 - val_loss: 0.6943 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.6230\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 0.6464 - accuracy: 0.6230 - val_loss: 0.6665 - val_accuracy: 0.6170 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.7690\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.5968 - accuracy: 0.7690 - val_loss: 0.6598 - val_accuracy: 0.6280 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7760\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.5832 - accuracy: 0.7760 - val_loss: 0.6591 - val_accuracy: 0.6290 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7760\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 5s 243ms/step - loss: 0.5801 - accuracy: 0.7760 - val_loss: 0.6588 - val_accuracy: 0.6290 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7780\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.5794 - accuracy: 0.7780 - val_loss: 0.6588 - val_accuracy: 0.6290 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1840/2510324021.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# TRAIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#print(\"shapes: \", X_train_p.shape, X_test_p.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRNN_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m      \u001b[1;31m### LOGGING INIT - RNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# GET the index of the highest test ACCURACY where the RNN model stopped to TRAIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ITU-BOOK\\2ndYearProject-NLP\\neuralnetworks.py\u001b[0m in \u001b[0;36mRNN_train\u001b[1;34m(X_train_p, y_train, X_test, y_test, tokenizer, maxlen)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     history = model.fit(X_train_p, y_train, validation_data=(X_test, y_test), \n\u001b[0m\u001b[0;32m     51\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m-> 2955\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3292\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                                    graph_function)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3128\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1134\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1136\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m   1137\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[0;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1312\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2888\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3688\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3689\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[1;32m--> 530\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1079\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    666\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m     \u001b[0mforward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m     \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    642\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[0;32m    643\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[1;32m--> 644\u001b[1;33m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    645\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    636\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    680\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    681\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 680\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    681\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    382\u001b[0m       body_graph.outputs, body_graph.inputs, grads) if grad is not None])\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m   body_grad_graph, args = _create_grad_func(\n\u001b[0m\u001b[0;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[1;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;31m# Note: The returned function does not have `args` in the list of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m   \u001b[1;31m# `external_captures`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m       \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    686\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m       \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[1;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[0;32m    742\u001b[0m   \u001b[1;31m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m   \u001b[1;31m# TODO(srbs): Mark GradientsHelper as public?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m   grad_outs = gradients_util._GradientsHelper(\n\u001b[0m\u001b[0;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m       unconnected_gradients=\"zero\")\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    680\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    681\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 680\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    681\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_SigmoidGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msigmoid_grad\u001b[1;34m(y, dy, name)\u001b[0m\n\u001b[0;32m   9489\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9490\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9491\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   9492\u001b[0m         \"SigmoidGrad\", y=y, dy=dy, name=name)\n\u001b[0;32m   9493\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    738\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   1033\u001b[0m           compute_device=compute_device)\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1035\u001b[1;33m     return super(_WhileBodyGradFuncGraph, self)._create_op_internal(\n\u001b[0m\u001b[0;32m   1036\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    691\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3774\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3775\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3776\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3777\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2181\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2182\u001b[1;33m     \u001b[0mnum_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationNumOutputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2183\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2184\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### INIT RESULTS\n",
    "results, time = f.init_log_for_training()\n",
    "\n",
    "for data_set in data_sets:\n",
    "    # Tokenizer\n",
    "    labels = data_set[0]\n",
    "\n",
    "    tokenizer = pp.tokenizer_init(data_set[1], data_set[2])\n",
    "    Train = tokenizer.texts_to_sequences(data_set[1])\n",
    "    Test = tokenizer.texts_to_sequences(data_set[2])\n",
    "        # Sequencer \n",
    "    X_train_p = pp.sequence_pad(Train) # there are several attributes which can be defined, basic = first 50 words \n",
    "    X_test_p = pp.sequence_pad(Test)\n",
    "        \n",
    "        # TRAIN\n",
    "    #print(\"shapes: \", X_train_p.shape, X_test_p.shape)\n",
    "    history, model = nn.RNN_train(X_train_p, y_train, X_test_p, y_test, tokenizer)\n",
    "     ### LOGGING INIT - RNN\n",
    "    # GET the index of the highest test ACCURACY where the RNN model stopped to TRAIN\n",
    "    max_value = max(history.history['val_accuracy'])\n",
    "    max_index = history.history['val_accuracy'].index(max_value)\n",
    "    # append\n",
    "    \n",
    "    new_row = {'Running ID':save_time, \n",
    "           \"Model Name\":\"RNN\", \n",
    "          \"Expand Contractions\":labels[0],\n",
    "          \"Basic Preprocessing\":labels[1],\n",
    "          \"Grammar Correction\":labels[2],\n",
    "           \"Simplify Negotiations\": labels[3],\n",
    "          \"Lemmatize\": labels[4],\n",
    "          \"Remove Stop Words\": labels[5],\n",
    "          \"No. of Sentences\": len(data_sets[c][1]),\n",
    "          \"Train Accuracy STOP\": history.history['accuracy'][max_index],\n",
    "          \"Test Accuracy STOP\": history.history['val_accuracy'][max_index],\n",
    "          \"Train Loss STOP\": history.history['loss'][max_index],\n",
    "          \"Test Loss STOP\": history.history['val_loss'][max_index]}\n",
    "    \n",
    "    results = results.append(new_row, ignore_index=True)\n",
    "    # maybe we dont need it in every round but how knows\n",
    "    try:\n",
    "        results.to_csv(\"results/results_\"+time+\".csv\")\n",
    "    except: \n",
    "        continue \n",
    "    \n",
    "# save results again\n",
    "results.to_csv(\"results/results_\"+time+\".csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073b415",
   "metadata": {},
   "source": [
    "# Leave it in here for experimenting purpose: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a57f5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Combination\n",
      ":  [0, 1, 0, 0, 0, 0]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 175ms/step - loss: 1.2002 - accuracy: 0.5320 - val_loss: 0.6855 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.5910\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.6491 - accuracy: 0.5910 - val_loss: 0.6657 - val_accuracy: 0.6240 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7610\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.6129 - accuracy: 0.7610 - val_loss: 0.6637 - val_accuracy: 0.6260 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.7640\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.6038 - accuracy: 0.7640 - val_loss: 0.6633 - val_accuracy: 0.6280 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.7680\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.6018 - accuracy: 0.7680 - val_loss: 0.6632 - val_accuracy: 0.6270 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7680\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.6013 - accuracy: 0.7680 - val_loss: 0.6631 - val_accuracy: 0.6270 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n",
      "##### Combination\n",
      ":  [0, 1, 0, 0, 0, 1]\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 176ms/step - loss: 1.6578 - accuracy: 0.5050 - val_loss: 0.6944 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.5680\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 0.6666 - accuracy: 0.5680 - val_loss: 0.6800 - val_accuracy: 0.5850 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6930\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 0.6259 - accuracy: 0.6930 - val_loss: 0.6776 - val_accuracy: 0.5860 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.6990\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.6167 - accuracy: 0.6990 - val_loss: 0.6771 - val_accuracy: 0.5900 - lr: 4.0000e-05\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.6990\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.6143 - accuracy: 0.6990 - val_loss: 0.6770 - val_accuracy: 0.5900 - lr: 8.0000e-06\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7000\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 0.6138 - accuracy: 0.7000 - val_loss: 0.6770 - val_accuracy: 0.5900 - lr: 1.6000e-06\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "'''### INIT RESULTS\n",
    "results, time = f.init_log_for_training()\n",
    "for c in range(2):\n",
    "    # Tokenizer\n",
    "    labels = data_sets[c][0]\n",
    "    print(\"##### Combination\\n: \", data_sets[c][0])\n",
    "    tokenizer = pp.tokenizer_init(data_sets[c][1], data_sets[c][2])\n",
    "    Train = tokenizer.texts_to_sequences(data_sets[c][1])\n",
    "    Test = tokenizer.texts_to_sequences(data_sets[c][2])\n",
    "        # Sequencer \n",
    "    X_train_p = pp.sequence_pad(Train) # there are several attributes which can be defined, basic = first 50 words \n",
    "    X_test_p = pp.sequence_pad(Test)\n",
    "        \n",
    "    # TRAIN RNN\n",
    "    history, model = nn.RNN_train(X_train_p, y_train, X_test_p, y_test, tokenizer)\n",
    "\n",
    "    ### LOGGING INIT - RNN\n",
    "    # GET the index of the highest test ACCURACY where the RNN model stopped to TRAIN\n",
    "    max_value = max(history.history['val_accuracy'])\n",
    "    max_index = history.history['val_accuracy'].index(max_value)\n",
    "    # append\n",
    "    \n",
    "    new_row = {'Running ID':save_time, \n",
    "           \"Model Name\":\"RNN\", \n",
    "          \"Expand Contractions\":labels[0],\n",
    "          \"Basic Preprocessing\":labels[1],\n",
    "          \"Grammar Correction\":labels[2],\n",
    "           \"Simplify Negotiations\": labels[3],\n",
    "          \"Lemmatize\": labels[4],\n",
    "          \"Remove Stop Words\": labels[5],\n",
    "          \"No. of Sentences\": len(data_sets[c][1]),\n",
    "          \"Train Accuracy STOP\": history.history['accuracy'][max_index],\n",
    "          \"Test Accuracy STOP\": history.history['val_accuracy'][max_index],\n",
    "          \"Train Loss STOP\": history.history['loss'][max_index],\n",
    "          \"Test Loss STOP\": history.history['val_loss'][max_index]}\n",
    "    \n",
    "    results = results.append(new_row, ignore_index=True)\n",
    "    \n",
    "# save results\n",
    "results.to_csv(\"results/results_\"+time+\".csv\") '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
