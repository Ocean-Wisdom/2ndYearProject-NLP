{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0577d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "\n",
    "# word to idx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a9d45",
   "metadata": {},
   "source": [
    "1 load our model <br>\n",
    "2 Load the word to idx saved object <br>\n",
    "3 Find 100 sentencies, or write them. Also with tags ( positive-negative) <br>\n",
    "4 Try to fuck it up ( swap the meaning, like \"good\" turn into \"not good\" and check the result <br>\n",
    "5 Check accuracy, report hard cases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51596031",
   "metadata": {},
   "source": [
    "Examples from checklist repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e190ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BD86DDAE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.99174494]\n",
      " [0.28501403]]\n"
     ]
    }
   ],
   "source": [
    "# Sentencies\n",
    "Train = ['This is a good day', 'what a hell is going on with the sound of the guitar? I never ever heard this shit before, unbeliveable!']\n",
    "#Train = ['This is bullshit, it sound like an old creppy dog']\n",
    "Labels = ['positive','negative']\n",
    "#Labels = ['negative']\n",
    "\n",
    "# labels to idx\n",
    "labels = []\n",
    "for i in Labels:\n",
    "    if i == \"positive\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "\n",
    "# load our model\n",
    "model = keras.models.load_model('model/2022-3-28-10-35-36')\n",
    "\n",
    "# load our word to idx\n",
    "sequencer = pickle.load( open( \"model/text_to_seq.p\", \"rb\" ) )\n",
    "sequencer = pickle.loads(sequencer)\n",
    "\n",
    "# Transform the example sentencies for idx\n",
    "Train = sequencer.transform(Train)\n",
    "\n",
    "# padding apply\n",
    "def sequence_pad(sequence, padding='pre', maxlen=50):\n",
    "    res = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        sequence,\n",
    "        maxlen=maxlen,\n",
    "        dtype='int32',\n",
    "        padding=padding,\n",
    "        truncating='pre',\n",
    "        value=0.0)\n",
    "    return res\n",
    "padding = \"post\"\n",
    "maxlen = 50\n",
    "X_train_p = sequence_pad(Train, padding=padding, maxlen=maxlen)\n",
    "\n",
    "# prediction\n",
    "res = model.predict(X_train_p)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb1c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
